---
title: "AVE_Notebook"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
library(dplyr)
library(lubridate)
renfeDF <- read.csv(file="~/Documents/GitHub/AVE-Study/renfe.csv")
renfeDF <- na.omit(renfeDF) 
renfeDF <- filter(renfeDF, price != 0)
renfeDF$insert_date <- ymd_hms(renfeDF$insert_date)
renfeDF$start_date <- ymd_hms(renfeDF$start_date)
renfeDF$end_date <- ymd_hms(renfeDF$end_date)


#' @import lattice
#' @import chron
#' @importFrom grid grid.lines gpar
#' @importFrom grDevices colorRampPalette

##############################################################################
#                        Calendar Heatmap                                    #
#                                by                                          #
#                         Paul Bleicher                                      #
# an R version of a graphic from:                                            #
# http://stat-computing.org/dataexpo/2009/posters/wicklin-allison.pdf        #
#  requires lattice, chron, grid packages                                    #
############################################################################## 
#
# https://github.com/iascchen/VisHealth/blob/master/R/calendarHeat.R
#
#
## calendarHeat: An R function to display time-series data as a calendar heatmap 
## Copyright 2009 Humedica. All rights reserved.

## This program is free software; you can redistribute it and/or modify
## it under the terms of the GNU General Public License as published by
## the Free Software Foundation; either version 2 of the License, or
## (at your option) any later version.

## This program is distributed in the hope that it will be useful,
## but WITHOUT ANY WARRANTY; without even the implied warranty of
## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
## GNU General Public License for more details.

## You can find a copy of the GNU General Public License, Version 2 at:
## http://www.gnu.org/licenses/gpl-2.0.html

calendarHeat <- function(dates, 
                         values, 
                         ncolors=99, 
                         color="r2g", 
                         varname="Values",
                         date.form = "%Y-%m-%d", ...) {
  if (class(dates) == "character" | class(dates) == "factor" ) {
    dates <- strptime(dates, date.form)
  }
  caldat <- data.frame(value = values, dates = dates)
  min.date <- as.Date(paste(format(min(dates), "%Y"),
                            "-1-1",sep = ""))
  max.date <- as.Date(paste(format(max(dates), "%Y"),
                            "-12-31", sep = ""))
  dates.f <- data.frame(date.seq = seq(min.date, max.date, by="days"))
  
  # Merge moves data by one day, avoid
  caldat <- data.frame(date.seq = seq(min.date, max.date, by="days"), value = NA)
  dates <- as.Date(dates) 
  caldat$value[match(dates, caldat$date.seq)] <- values
  
  caldat$dotw <- as.numeric(format(caldat$date.seq, "%w"))
  caldat$woty <- as.numeric(format(caldat$date.seq, "%U")) + 1
  caldat$yr <- as.factor(format(caldat$date.seq, "%Y"))
  caldat$month <- as.numeric(format(caldat$date.seq, "%m"))
  yrs <- as.character(unique(caldat$yr))
  d.loc <- as.numeric()                        
  for (m in min(yrs):max(yrs)) {
    d.subset <- which(caldat$yr == m)  
    sub.seq <- seq(1,length(d.subset))
    d.loc <- c(d.loc, sub.seq)
  }  
  caldat <- cbind(caldat, seq=d.loc)
  
  #color styles
  r2b <- c("#0571B0", "#92C5DE", "#F7F7F7", "#F4A582", "#CA0020") #red to blue                                                                               
  r2g <- c("#D61818", "#FFAE63", "#FFFFBD", "#B5E384")   #red to green
  w2b <- c("#045A8D", "#2B8CBE", "#74A9CF", "#BDC9E1", "#F1EEF6")   #white to blue
  
  assign("col.sty", get(color))
  calendar.pal <- colorRampPalette((col.sty), space = "Lab")
  def.theme <- lattice.getOption("default.theme")
  cal.theme <-
    function() {  
      theme <-
        list(
          strip.background = list(col = "transparent"),
          strip.border = list(col = "transparent"),
          axis.line = list(col="transparent"),
          par.strip.text=list(cex=0.8))
    }
  lattice.options(default.theme = cal.theme)
  yrs <- (unique(caldat$yr))
  nyr <- length(yrs)
  print(cal.plot <- levelplot(value~woty*dotw | yr, data=caldat,
                              as.table=TRUE,
                              aspect=.12,
                              layout = c(1, nyr%%7),
                              between = list(x=0, y=c(1,1)),
                              strip=TRUE,
                              main = paste("Calendar Heat Map of ", varname, sep = ""),
                              scales = list(
                                x = list(
                                  at= c(seq(2.9, 52, by=4.42)),
                                  labels = month.abb,
                                  alternating = c(1, rep(0, (nyr-1))),
                                  tck=0,
                                  cex = 0.7),
                                y=list(
                                  at = c(0, 1, 2, 3, 4, 5, 6),
                                  labels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday",
                                             "Friday", "Saturday"),
                                  alternating = 1,
                                  cex = 0.6,
                                  tck=0)),
                              xlim =c(0.4, 54.6),
                              ylim=c(6.6,-0.6),
                              cuts= ncolors - 1,
                              col.regions = (calendar.pal(ncolors)),
                              xlab="" ,
                              ylab="",
                              colorkey= list(col = calendar.pal(ncolors), width = 0.6, height = 0.5),
                              subscripts=TRUE
  ) )
  panel.locs <- trellis.currentLayout()
  for (row in 1:nrow(panel.locs)) {
    for (column in 1:ncol(panel.locs))  {
      if (panel.locs[row, column] > 0)
      {
        trellis.focus("panel", row = row, column = column,
                      highlight = FALSE)
        xyetc <- trellis.panelArgs()
        subs <- caldat[xyetc$subscripts,]
        dates.fsubs <- caldat[caldat$yr == unique(subs$yr),]
        y.start <- dates.fsubs$dotw[1]
        y.end   <- dates.fsubs$dotw[nrow(dates.fsubs)]
        dates.len <- nrow(dates.fsubs)
        adj.start <- dates.fsubs$woty[1]
        
        for (k in 0:6) {
          if (k < y.start) {
            x.start <- adj.start + 0.5
          } else {
            x.start <- adj.start - 0.5
          }
          if (k > y.end) {
            x.finis <- dates.fsubs$woty[nrow(dates.fsubs)] - 0.5
          } else {
            x.finis <- dates.fsubs$woty[nrow(dates.fsubs)] + 0.5
          }
          grid.lines(x = c(x.start, x.finis), y = c(k -0.5, k - 0.5), 
                     default.units = "native", gp=gpar(col = "grey", lwd = 1))
        }
        if (adj.start <  2) {
          grid.lines(x = c( 0.5,  0.5), y = c(6.5, y.start-0.5), 
                     default.units = "native", gp=gpar(col = "grey", lwd = 1))
          grid.lines(x = c(1.5, 1.5), y = c(6.5, -0.5), default.units = "native",
                     gp=gpar(col = "grey", lwd = 1))
          grid.lines(x = c(x.finis, x.finis), 
                     y = c(dates.fsubs$dotw[dates.len] -0.5, -0.5), default.units = "native",
                     gp=gpar(col = "grey", lwd = 1))
          if (dates.fsubs$dotw[dates.len] != 6) {
            grid.lines(x = c(x.finis + 1, x.finis + 1), 
                       y = c(dates.fsubs$dotw[dates.len] -0.5, -0.5), default.units = "native",
                       gp=gpar(col = "grey", lwd = 1))
          }
          grid.lines(x = c(x.finis, x.finis), 
                     y = c(dates.fsubs$dotw[dates.len] -0.5, -0.5), default.units = "native",
                     gp=gpar(col = "grey", lwd = 1))
        }
        for (n in 1:51) {
          grid.lines(x = c(n + 1.5, n + 1.5), 
                     y = c(-0.5, 6.5), default.units = "native", gp=gpar(col = "grey", lwd = 1))
        }
        x.start <- adj.start - 0.5
        
        if (y.start > 0) {
          grid.lines(x = c(x.start, x.start + 1),
                     y = c(y.start - 0.5, y.start -  0.5), default.units = "native",
                     gp=gpar(col = "black", lwd = 1.75))
          grid.lines(x = c(x.start + 1, x.start + 1),
                     y = c(y.start - 0.5 , -0.5), default.units = "native",
                     gp=gpar(col = "black", lwd = 1.75))
          grid.lines(x = c(x.start, x.start),
                     y = c(y.start - 0.5, 6.5), default.units = "native",
                     gp=gpar(col = "black", lwd = 1.75))
          if (y.end < 6  ) {
            grid.lines(x = c(x.start + 1, x.finis + 1),
                       y = c(-0.5, -0.5), default.units = "native",
                       gp=gpar(col = "black", lwd = 1.75))
            grid.lines(x = c(x.start, x.finis),
                       y = c(6.5, 6.5), default.units = "native",
                       gp=gpar(col = "black", lwd = 1.75))
          } else {
            grid.lines(x = c(x.start + 1, x.finis),
                       y = c(-0.5, -0.5), default.units = "native",
                       gp=gpar(col = "black", lwd = 1.75))
            grid.lines(x = c(x.start, x.finis),
                       y = c(6.5, 6.5), default.units = "native",
                       gp=gpar(col = "black", lwd = 1.75))
          }
        } else {
          grid.lines(x = c(x.start, x.start),
                     y = c( - 0.5, 6.5), default.units = "native",
                     gp=gpar(col = "black", lwd = 1.75))
        }
        
        if (y.start == 0 ) {
          if (y.end < 6  ) {
            grid.lines(x = c(x.start, x.finis + 1),
                       y = c(-0.5, -0.5), default.units = "native",
                       gp=gpar(col = "black", lwd = 1.75))
            grid.lines(x = c(x.start, x.finis),
                       y = c(6.5, 6.5), default.units = "native",
                       gp=gpar(col = "black", lwd = 1.75))
          } else {
            grid.lines(x = c(x.start + 1, x.finis),
                       y = c(-0.5, -0.5), default.units = "native",
                       gp=gpar(col = "black", lwd = 1.75))
            grid.lines(x = c(x.start, x.finis),
                       y = c(6.5, 6.5), default.units = "native",
                       gp=gpar(col = "black", lwd = 1.75))
          }
        }
        for (j in 1:12)  {
          last.month <- max(dates.fsubs$seq[dates.fsubs$month == j])
          x.last.m <- dates.fsubs$woty[last.month] + 0.5
          y.last.m <- dates.fsubs$dotw[last.month] + 0.5
          grid.lines(x = c(x.last.m, x.last.m), y = c(-0.5, y.last.m),
                     default.units = "native", gp=gpar(col = "black", lwd = 1.75))
          if ((y.last.m) < 6) {
            grid.lines(x = c(x.last.m, x.last.m - 1), y = c(y.last.m, y.last.m),
                       default.units = "native", gp=gpar(col = "black", lwd = 1.75))
            grid.lines(x = c(x.last.m - 1, x.last.m - 1), y = c(y.last.m, 6.5),
                       default.units = "native", gp=gpar(col = "black", lwd = 1.75))
          } else {
            grid.lines(x = c(x.last.m, x.last.m), y = c(- 0.5, 6.5),
                       default.units = "native", gp=gpar(col = "black", lwd = 1.75))
          }
        }
      }
    }
    trellis.unfocus()
  } 
  lattice.options(default.theme = def.theme)
}

```

En el siguiente documento se va a llevar a cabo un análisis de los datos sobre el ajuste de los precios a lo largo del tiempo que van adoptando los tiques del Renfe AVE, según cambia la oferta y demanda.

Para visualizar como son los datos a analizar, usamos una entrada aleatoria a los datos recuperando 10 filas aleatorias.

```{r paged.print=TRUE}
renfeDF[sample(nrow(renfeDF), 10),]
reducedRenfeDF <- renfeDF[sample(nrow(renfeDF), 10000),]
```

```{r paged.print=TRUE}
library(psych)
describe(renfeDF$price)
```

En este primer analisis podemos determinar la media, mediana, deviacion estandar, kurtosis y el rango de los datos sin discriminar ninguna variable cualitativa. Podemos ver que la mediana de los precios es 58,15 Euros y que el maximo de todos los datos es 342 Euros.

Vamos a empezar a analizar las variables categoricas de los datos, analizando el precio en funcion del tipo de asiento (Turista, Preferente, Cama, ...)

```{r paged.print=FALSE}
describeBy(renfeDF$price, renfeDF$train_type)
```
```{r paged.print=FALSE}
describeBy(renfeDF$price, renfeDF$train_class)
```
```{r paged.print=FALSE}
describeBy(renfeDF$price, months(as.Date(renfeDF$start_date)))
```

A continuacion vamos a utilizar la libreria fitdistrplus para ver si los datos se pueden asemejar a una distribucion de datos conocida. Para eso utilizamos el comando descdist que nos presenta un grafico de Cullen y Frey.

```{r message=FALSE, warning=FALSE}
library(fitdistrplus)
descdist(renfeDF$price)
```
Vemos que los datos se podrian asemejar a una lognormal o incluso a una distribucion gamma. Vamos a decidir numericamente si los datos se pueden asemejar a una distribucion normal usando el test de Shapiro-Wilkinson.


Aun asi vamos a representar los datos en un histograma para descartar que se trate de una distibucion normal. Para ello usamos la libreria rcompanion.
 
```{r message=FALSE, warning=FALSE}
library(rcompanion)
plotNormalHistogram(renfeDF$price)
```

Ahora hacemos el test Shapiro-Wilkinson para tener confirmacion numerica de que no se trata de una normal.


```{r warning=FALSE}
library(fitdistrplus)
shapiro.test(renfeDF$price[1:5000])
```
Podemos asumir que los datos no se asemejan a una normal ya que el p-value obtenido del test de Shapiro-Wilkinson es menor que 0.05.

Ahora vamos a modificar los datos usando una transformacion logaritmica para ver si conseguimos que se asemeje a una distribucion normal.


```{r echo=FALSE, message=FALSE, warning=FALSE}
library(fitdistrplus)
descdist(log(renfeDF$price))
```

Al hacer la transformacion de los datos podemos ver que los datos ahora se asemejan a una normal tras realizar una transformacion logaritmica sobre el precio. Ahora mostramos un histograma sobre los datos transformados para ver como se asemeja a una curva normal.

```{r message=FALSE, warning=FALSE}
plotNormalHistogram(log(renfeDF$price))
```

Podemos ver que excepto un par de valores que sobresalen por la curva normal, el conjunto de datos se comporta como una curva normal.

```{r message=FALSE, warning=FALSE}
library(car)
qqPlot(renfeDF[sample(nrow(renfeDF), 100000),]$price)
```

Haciendo el Q-Q plot vemos que hay muchos valores que no se asemejan a la recta normal, lo cual concuerda con las previas conclusiones de que los datos de precio, no se asemejan a una distribucion normal. En cambio si repetimos este mismo grafico con una transformacion logaritmica obtenemos unos resultados que se pueden aproximar a una normal. Para ver con mas precision los datos extraemos 100 filas de los datos de manera aleatoria por lo que hacemos 3 veces el mismo grafico para asegurar que los datos de verdad se asemejan a una normal.


```{r message=FALSE, warning=FALSE, paged.print=TRUE}
qqPlot(log(renfeDF[sample(nrow(renfeDF), 100),]$price))
qqPlot(log(renfeDF[sample(nrow(renfeDF), 100),]$price))
qqPlot(log(renfeDF[sample(nrow(renfeDF), 100),]$price))
```

Vamos a ver la cantidad de viajes en cada mes 

```{r message=FALSE, warning=FALSE}

numOfTripsApril <- count(renfeDF %>% filter(months(as.Date(renfeDF$start_date)) == "April" ))
numOfTripsApril <- numOfTripsApril$n
renfeDFApril <- renfeDF %>% filter(months(as.Date(renfeDF$start_date)) == "April")
medianApril <- median(renfeDFApril$price)
numOfTrips <- numOfTripsApril


numOfTripsAugust <- count(renfeDF %>% filter(months(as.Date(renfeDF$start_date)) == "August" ))
numOfTripsAugust <- numOfTripsAugust$n
renfeDFAugust <- renfeDF %>% filter(months(as.Date(renfeDF$start_date)) == "August")
medianAugust <- median(renfeDFAugust$price)
numOfTrips <- c(numOfTrips, numOfTripsAugust)


numOfTripsJuly <- count(renfeDF %>% filter(months(as.Date(renfeDF$start_date)) == "July" ))
numOfTripsJuly <- numOfTripsJuly$n
renfeDFJuly <- renfeDF %>% filter(months(as.Date(renfeDF$start_date)) == "July")
medianJuly <- median(renfeDFJuly$price)
numOfTrips <- c(numOfTrips, numOfTripsJuly)

numOfTripsJune <- count(renfeDF %>% filter(months(as.Date(renfeDF$start_date)) == "June" ))
numOfTripsJune <- numOfTripsJune$n
renfeDFJune <- renfeDF %>% filter(months(as.Date(renfeDF$start_date)) == "June")
medianJune <- median(renfeDFJune$price)
numOfTrips <- c(numOfTrips, numOfTripsJune)


numOfTripsMay <- count(renfeDF %>% filter(months(as.Date(renfeDF$start_date)) == "May" ))
numOfTripsMay <- numOfTripsMay$n
renfeDFMay <- renfeDF %>% filter(months(as.Date(renfeDF$start_date)) == "May")
medianMay <- median(renfeDFMay$price)
numOfTrips <- c(numOfTrips, numOfTripsMay)

numOfTripsOctober <- count(renfeDF %>% filter(months(as.Date(renfeDF$start_date)) == "October" ))
numOfTripsOctober <- numOfTripsOctober$n
renfeDFOctober <- renfeDF %>% filter(months(as.Date(renfeDF$start_date)) == "October")
medianOctober <- median(renfeDFOctober$price)
numOfTrips <- c(numOfTrips, numOfTripsOctober)

numOfTripsSeptember <- count(renfeDF %>% filter(months(as.Date(renfeDF$start_date)) == "September" ))
numOfTripsSeptember <- numOfTripsSeptember$n
renfeDFSeptember <- renfeDF %>% filter(months(as.Date(renfeDF$start_date)) == "September")
medianSeptember <- median(renfeDFSeptember$price)
numOfTrips <- c(numOfTrips, numOfTripsSeptember)

tempDF <- data.frame(numOfTrips, c("April", "August", "July", "June", "May", "October", "September"), c(medianApril,medianAugust,medianJuly,medianJune,medianMay,medianOctober,medianSeptember))
library(tidyverse)
tempDF <- tempDF %>% rename(months=c..April....August....July....June....May....October....September..)
tempDF <- tempDF %>% rename(medianPrice=c.medianApril..medianAugust..medianJuly..medianJune..medianMay..)



h1 <- ggplot(data=tempDF, aes(x=months, y=numOfTrips, color=months)) +
  geom_bar(stat="identity", fill="gray86")
h1 <- h1 + theme_minimal()
h1 <- h1 + ggtitle("Distribucion de Viajes segun el Mes")
h1 <- h1 + geom_hline(yintercept=653478,linetype="dashed",color="red")
h1 <- h1 + labs(y= "Numero de Viajes", x= "", colour="", fill="")
h1




h3 <- ggplot(data=tempDF, aes(x=months, y=medianPrice, color=months)) +
  geom_bar(stat="identity", fill="gray86")
h3 <- h3 + theme_minimal()
h3 <- h3 + geom_hline(yintercept=53.4,linetype="dashed",color="red")
h3 <- h3 + ggtitle("Precio mediano de los Viajes segun el Mes")
h3 <- h3 + labs(y= "Precio mediano", x= "", colour="", fill="")
h3


yes <- renfeDF[sample(nrow(renfeDF), 500),]
h2 <- ggplot(yes)
h2 <- h2 + geom_point(aes(x=price,y=train_class,color=fare))
h2 <- h2 + labs(y= "", x= "Precio", colour="", fill="")
h2





```


```{r}
library(polycor)
hetcor(tempDF)
```
Si r=0.476 Algunos puntos están cerca de la línea, pero otros puntos están lejos de ella, lo que indica que solo existe una relación lineal moderada entre las variables.

Vemos que la variable mes afecta mucho mas a la variable precio que la variable numero de viajes.

```{r}
reducedRenfeDF2 <- data.frame(reducedRenfeDF$origin,reducedRenfeDF$price)
hetcor(reducedRenfeDF2)
```

Vemos que no hay correlacion entre el origen y el precio, ni el destino y el precio.

```{r}
reducedRenfeDF2 <- data.frame(reducedRenfeDF$destination,reducedRenfeDF$price)
hetcor(reducedRenfeDF2)
reducedRenfeDF2 <- data.frame(reducedRenfeDF$destination,reducedRenfeDF$price)
hetcor(reducedRenfeDF2)
```



```{r}
library(ggmap)
test <- paste(renfeDF$origin,renfeDF$destination)
test <- unique(test)
register_google(key = "AIzaSyBtYqHr5ATL0s8N4BudEH_lS5dGnhV4NNw")
test2 <- str_split(test, " ")

cont <- 1
vectorkm <- c(seq(length(test2)))
while (cont <= length(test2))
{
  it <- test2[[cont]]
  origen <- it[1]
  origen <- paste(origen, ", Spain")
  destino <- it[2]
  destino <- paste(destino, ", Spain")
  dist <- mapdist(from = origen, to = destino)
  vectorkm[cont] <- dist$km
  cont <- cont + 1 
}

distances<- data.frame (test,vectorkm)


cont <- 1
tempa <- data.frame()
while(cont <= length(distances$test))
{
  
  
  temp<-renfeDF %>% filter(paste(renfeDF$origin,renfeDF$destination)==test[cont])
  temp$distance=distances$vectorkm[cont]
  tempa <- rbind(tempa,temp)
  cont <- cont + 1
}


renfeDF <- tempa
remove(tempa)
reducedRenfeDF <- renfeDF[sample(nrow(renfeDF), 10000),]
h5 <- ggplot(reducedRenfeDF)
h5 <- h5 + geom_point(aes(x=price,y=distance, colour=train_type))
h5 <- h5 + geom_smooth(method= "lm" ,aes(x=price,y=distance))
h5

h6 <- ggplot(reducedRenfeDF)
h6 <- h6 + geom_point(aes(x=price,y=distance, colour=train_type))
h6 <- h6 + geom_smooth(aes(x=price,y=distance))
h6

```

Vamos a analizar el precio segun el dia del mes y el mes del año

```{r}
temp1 <- renfeDF


temp1$yday = as.POSIXlt(renfeDF$start_date)$yday
temp1 <- temp1[order(temp1$yday),]
uniqueYday = unique(temp1$yday)
medPrices <- c()
for (ydaya in uniqueYday) {
  renfeDFyday = filter(temp1, yday == ydaya)
  renfeDFyday$mdprice = median(renfeDFyday$price)
  medPrices <- c(medPrices,renfeDFyday$mdprice)
}
temp1$mdprices = medPrices
remove(medPrices)

temp1$weekday = as.POSIXlt(renfeDF$start_date)$wday
temp1$weekdayf <- factor(temp1$weekday, levels = rev(0:6), labels = rev(c("Lun", "Mar", "Mie", "Jue", "Vie", "Sab", "Dom")),ordered = TRUE)

temp1$monthf <- factor(month(renfeDF$start_date),levels = as.character(1:12),labels = c("Ene","Feb","Mar","Abr","May","Jun", "Jul", "Ago", "Sep", "Oct", "Nov", "Dic"))

library(zoo)

temp1$yearmonth <- factor(as.yearmon(renfeDF$start_date))

temp1$week <- as.numeric(format(renfeDF$start_date, "%W"))

temp1<-ddply(temp1,.(yearmonth),transform,monthweek=1+week-min(week))

p <- ggplot(temp1, aes(monthweek, weekdayf, fill = temp1$mdprices)) + 
    geom_tile(colour = "white") + facet_grid(year(temp1$start_date)~monthf) + scale_fill_gradient(low="green", high="red") +  xlab("Week of Month") + ylab("") + ggtitle("Time-Series Calendar Heatmap: RENFE prices over the current year") + labs(fill = "Price")

p


```

Se va a mostrar un scaterplot de la distancia frente al precio para contemplar la distribución que siguen inicialmente:

```{r}
library(ggplot2)
library(tidyverse)
library(caret)
theme_set(theme_classic())

reducedRenfeDF <- renfeDF[sample(nrow(renfeDF), 500000),]

#80& son entrenamiento y 20% test
set.seed(123)
training.samples <- reducedRenfeDF$price %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data  <- reducedRenfeDF[training.samples, ]
test.data <- reducedRenfeDF[-training.samples, ]

ggplot(train.data, aes(distance, price) ) +
  geom_point() +
  stat_summary(fun.y=mean, colour="red", geom="line")
```

Se puede contemplar cómo no forman una distribución lineal, por tanto, se van a realizar modelos de regresión no lineal, para ver el cambio. Se comenzará utilizando una función logarítmica, ya que, se vio anteriormente que se aproximaba el precio a la logarítmica:


```{r}
library(ggplot2)
library(tidyverse)
library(caret)
theme_set(theme_classic())

set.seed(123)
training.samples <- reducedRenfeDF$price %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data  <- reducedRenfeDF[training.samples, ]
test.data <- reducedRenfeDF[-training.samples, ]

# Build the model
model <- lm(price ~ log(distance), data = train.data)
# Make predictions
predictions <- model %>% predict(test.data)
# Model performance
data.frame(
  RMSE = RMSE(predictions, test.data$price),
  R2 = R2(predictions, test.data$price)
)

ggplot(train.data, aes(distance, price) ) +
  geom_point() +
  stat_summary(fun.y=mean, colour="red", geom="line")

```

Ahora polynomial

```{r}
library(ggplot2)
library(tidyverse)
library(caret)
theme_set(theme_classic())


set.seed(123)
training.samples <- reducedRenfeDF$price %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data  <- reducedRenfeDF[training.samples, ]
test.data <- reducedRenfeDF[-training.samples, ]
# Build the model
model <- lm(price ~ poly(distance, 5, raw = TRUE), data = train.data)
# Make predictions
predictions <- model %>% predict(test.data)
# Model performance
data.frame(
  RMSE = RMSE(predictions, test.data$price),
  R2 = R2(predictions, test.data$price)
)

ggplot(train.data, aes(distance, price) ) +
  geom_point() +
  stat_smooth(method = lm, formula = y ~ poly(x, 5, raw = TRUE))
```

```{r}
library(lubridate)
reducedRenfeDF$insert_date <- ymd_hms(reducedRenfeDF$insert_date)
reducedRenfeDF$start_date <- ymd_hms(reducedRenfeDF$start_date)
reducedRenfeDF$end_date <- ymd_hms(reducedRenfeDF$end_date)

```

Como se vio anteriormente, la variable precio tiene poca relación lineal con el resto de variables. A continuación, se va a mostrar un scaterplot del precio con todas las variables, para ver una representación más clara del suceso anterior:

```{r}

library(ggplot2)
library(tidyverse)
library(caret)
library(grid)
theme_set(theme_classic())

#discretizacion de variables nominales
must_convert<-sapply(reducedRenfeDF,is.factor)       # logical vector telling if a variable needs to be displayed as numeric
renfeDF2<-sapply(reducedRenfeDF[,must_convert],unclass)    # data.frame of all categorical variables now displayed as numeric
reducedRenfeDF2<-cbind(reducedRenfeDF[,!must_convert],renfeDF2)        # complete data.frame with all variables put together


#60& son entrenamiento y 40% test
set.seed(123)
training.samples <- reducedRenfeDF2$price %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data  <- reducedRenfeDF2[training.samples, ]
test.data <- reducedRenfeDF2[-training.samples, ]

remove(renfeDF2)
remove(reducedRenfeDF2)

plot1 <- ggplot(train.data, aes(x=insert_date, y=price) ) +
geom_point(alpha = 1/15, color = 'blue')+
stat_smooth(color = 'Red')

plot2 <- ggplot(train.data, aes(x=origin, y=price) ) +
geom_point(alpha = 1/15, color = 'blue')+
stat_summary(fun.y=mean, colour="red", geom="line")

plot3 <- ggplot(train.data, aes(x=destination, y=price) ) +
geom_point(alpha = 1/15, color = 'blue')+
stat_summary(fun.y=mean, colour="red", geom="line")

plot4 <- ggplot(train.data, aes(x=start_date, y=price) ) +
geom_point(alpha = 1/15, color = 'blue')+
stat_smooth(color = 'Red')

plot5 <- ggplot(train.data, aes(x=end_date, y=price) ) +
geom_point(alpha = 1/15, color = 'blue')+
stat_smooth(color = 'Red')

plot6 <- ggplot(train.data, aes(x=train_type, y=price) ) +
geom_point(alpha = 1/15, color = 'blue')+
stat_summary(fun.y=mean, colour="red", geom="line")

plot7 <- ggplot(train.data, aes(x=train_class, y=price) ) +
geom_point(alpha = 1/15, color = 'blue')+
stat_summary(fun.y=mean, colour="red", geom="line")

plot8 <- ggplot(train.data, aes(x=fare, y=price) ) +
geom_point(alpha = 1/15, color = 'blue')+
stat_summary(fun.y=mean, colour="red", geom="line")

plot9 <- ggplot(train.data, aes(x=distance, y=price) ) +
geom_point(alpha = 1/15, color = 'blue')+
stat_summary(fun.y=mean, colour="red", geom="line")

library(gridExtra)
grid.arrange(plot1, plot2, plot3, ncol=3, nrow=1)
grid.arrange(plot4, plot5, plot6, ncol=3, nrow=1)
grid.arrange(plot7, plot8, plot9, ncol=3, nrow=1)
```

Se puede contemplar cómo no forman una distribución lineal, por tanto, se van a realizar modelos de regresión no lineal, para ver el cambio. Se comenzará utilizando una función logarítmica, ya que, se vio anteriormente que se aproximaba el precio a la logarítmica:


```{r}

library(ggplot2)
library(tidyverse)
library(caret)
theme_set(theme_classic())

#discretizacion de variables nominales
must_convert<-sapply(reducedRenfeDF,is.factor)       # logical vector telling if a variable needs to be displayed as numeric
renfeDF2<-sapply(reducedRenfeDF[,must_convert],unclass)    # data.frame of all categorical variables now displayed as numeric
reducedRenfeDF2<-cbind(reducedRenfeDF[,!must_convert],renfeDF2)        # complete data.frame with all variables put together


#60& entrenamiento y 20% test
set.seed(123)
training.samples <- reducedRenfeDF2$price %>%
  createDataPartition(p = 0.6, list = FALSE)
train.data  <- reducedRenfeDF2[training.samples, ]
test.data <- reducedRenfeDF2[-training.samples, ]

# Build the model
model <- lm(price ~ log(distance), data = train.data)
# Make predictions
predictions <- model %>% predict(test.data)
# Model performance
data.frame(
  RMSE = RMSE(predictions, test.data$price),
  R2 = R2(predictions, test.data$price)
)

remove(renfeDF2)
remove(reducedRenfeDF2)

plot1 <- ggplot(train.data, aes(x=insert_date, y=price)) +
geom_point(alpha = 1/15, color = 'blue')+
stat_smooth(color = 'Red', method = lm, formula = y ~ log(x))

plot2 <- ggplot(train.data, aes(x=origin, y=price)) +
geom_point(alpha = 1/15, color = 'blue')+
stat_smooth(color = 'Red', method = lm, formula = y ~ log(x))

plot3 <- ggplot(train.data, aes(x=destination, y=price)) +
geom_point(alpha = 1/15, color = 'blue')+
stat_smooth(color = 'Red', method = lm, formula = y ~ log(x))

plot4 <- ggplot(train.data, aes(x=start_date, y=price)) +
geom_point(alpha = 1/15, color = 'blue')+
stat_smooth(color = 'Red', method = lm, formula = y ~ log(x))

plot5 <- ggplot(train.data, aes(x=end_date, y=price)) +
geom_point(alpha = 1/15, color = 'blue')+
stat_smooth(color = 'Red', method = lm, formula = y ~ log(x))

plot6 <- ggplot(train.data, aes(x=train_type, y=price)) +
geom_point(alpha = 1/15, color = 'blue')+
stat_smooth(color = 'Red', method = lm, formula = y ~ log(x))

plot7 <- ggplot(train.data, aes(x=train_class, y=price)) +
geom_point(alpha = 1/15, color = 'blue')+
stat_smooth(color = 'Red', method = lm, formula = y ~ log(x))

plot8 <- ggplot(train.data, aes(x=fare, y=price)) +
geom_point(alpha = 1/15, color = 'blue')+
stat_smooth(color = 'Red', method = lm, formula = y ~ log(x))

plot9 <- ggplot(train.data, aes(x=distance, y=price)) +
geom_point(alpha = 1/15, color = 'blue')+
stat_smooth(color = 'Red', method = lm, formula = y ~ log(x))

library(gridExtra)
grid.arrange(plot1, plot2, plot3, ncol=3, nrow=1)
grid.arrange(plot4, plot5, plot6, ncol=3, nrow=1)
grid.arrange(plot7, plot8, plot9, ncol=3, nrow=1)
```

Ahora polynomial

```{r}
library(ggplot2)
library(tidyverse)
library(caret)
theme_set(theme_classic())

#discretizacion de variables nominales
must_convert<-sapply(reducedRenfeDF,is.factor)       # logical vector telling if a variable needs to be displayed as numeric
renfeDF2<-sapply(reducedRenfeDF[,must_convert],unclass)    # data.frame of all categorical variables now displayed as numeric
reducedRenfeDF2<-cbind(reducedRenfeDF[,!must_convert],renfeDF2)        # complete data.frame with all variables put together



#60& son entrenamiento y 40% test
set.seed(123)
training.samples <- reducedRenfeDF2$price %>%
  createDataPartition(p = 0.6, list = FALSE)
train.data  <- reducedRenfeDF2[training.samples, ]
test.data <- reducedRenfeDF2[-training.samples, ]

# Build the model
model <- lm(price ~ poly(distance, 5, raw = TRUE), data = train.data)
# Make predictions
predictions <- model %>% predict(test.data)
# Model performance
data.frame(
  RMSE = RMSE(predictions, test.data$price),
  R2 = R2(predictions, test.data$price)
)

remove(renfeDF2)
remove(reducedRenfeDF2)




plot1 <- ggplot(train.data, aes(x=origin, y=price) ) +
geom_point(alpha = 1/15, color = 'blue')+
stat_smooth(color = 'Red', method = lm, formula = y ~ poly(x, 5, raw = TRUE))

plot2 <- ggplot(train.data, aes(x=destination, y=price) ) +
geom_point(alpha = 1/15, color = 'blue')+
stat_smooth(color = 'Red', method = lm, formula = y ~ poly(x, 5, raw = TRUE))


plot3 <- ggplot(train.data, aes(x=train_type, y=price) ) +
geom_point(alpha = 1/15, color = 'blue')+
stat_smooth(color = 'Red', method = lm, formula = y ~ poly(x, 5, raw = TRUE))

plot4 <- ggplot(train.data, aes(x=train_class, y=price) ) +
geom_point(alpha = 1/15, color = 'blue')+
stat_smooth(color = 'Red', method = lm, formula = y ~ poly(x, 5, raw = TRUE))

plot5 <- ggplot(train.data, aes(x=fare, y=price) ) +
geom_point(alpha = 1/15, color = 'blue')+
stat_smooth(color = 'Red', method = lm, formula = y ~ poly(x, 5, raw = TRUE))

plot6 <- ggplot(train.data, aes(x=distance, y=price) ) +
geom_point(alpha = 1/15, color = 'blue')+
stat_smooth(color = 'Red', method = lm, formula = y ~ poly(x, 5, raw = TRUE))

library(gridExtra)
grid.arrange(plot1, plot2, plot3, ncol=3, nrow=1)
grid.arrange(plot4, plot5, plot6, ncol=3, nrow=1)
```




